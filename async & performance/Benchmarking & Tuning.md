# 基准和调优(Benchmarking & Tuning)
本卷的第五章在宏观的程序运行层面，阐述了一些关于 JS 性能优化相关的内容；而本章正好与其相呼应，在微观，即某一行表达式、语句的层面，再来探究下性能优化。

不过在开始之前，需要强调的是，这一章并非是要探索那些几度令开发者着迷的扣细节游戏 —— 到底是 `++a` 还是 `a++` 在某些个 JS 引擎中执行的更快 —— 分析并测试实现某行代码的多个选项，然后得出谁更快的这种收效甚微的结论。而比这更重要的是，明白到底哪些实现，对 JS 的性能来说才是关键，哪些不是，并且很好的区分这两者。

在实现这个目标之前，我们需要先了解一下如何正确可靠的测试 JS 的性能，否则的话，就会有 “成千上万吨” 的误解和神话的洪流，把你冲击得头晕脑胀，不知所向。

## 基准(Benchmarking)
假如现在有个任务是要求在 JS 中测试某一段代码的执行时间，估计大部分的开发者都会这么做：

```js
var start = (new Date()).getTime();

// some code

var end = (new Date()).getTime();

console.log('Duration: ', end - start);
```

有这样的想法和念头不足为奇，但它有多么不靠谱呢？

- 首先，如果结果为 `0`，你可能会以为它执行的时间少于1毫秒，所以才会这样 —— 想多了！很多浏览器都没有精确到毫秒的能力，比如 IE 浏览器只能精确到15毫秒，这也就是说，执行的代码要是少于这个数，只能得到 `0`。

- 而且，无论最终结果是啥，这都是单次的耗时，你不能确保每次执行，都和这个结果一致。比如 JS 引擎或者操作系统在这个时刻干涉了代码的运行，那后续的耗时是否就比这次快呢？

- 再者，如果结果是 `4`，那你就肯定耗费了4毫秒吗？万一在获取 `start` 或者 `end` 的时间戳的时候遇到了延迟的情况呢？

- 更为头疼的是，你根本不知道你特定的代码片段，是否在这个浏览器环境中被优化过，而一旦被放到实际的执行环境中，这些优化就失效了，最终实际的耗时比你测试的要长。

因此，用这样的方法👆🏻，得到的测试数据，对于实际的生产没有任何指导意义。

### 重复(Repetition)
好，那你说写个 loop 来重复100次，最终得出了137毫秒，然后再除以100，得出了单次运行1.37毫秒的结果，这样总可以了吧？

真的可以吗？别被数学耍的小把戏给欺骗了 —— 100次循环迭代，如果有几个异常情况(outliers)，无论是高还是低，都会严重扭曲平均的结果，而后若是你反复使用这个结论作为依据的时候，还会进一步扩大这个偏差。

另一个办法是不固定次数，而是用运行总时间来进行测量 —— 循环遍历你的代码片段，直到到达某个时间节点，而后根据迭代的总次数来推断出单次耗时。可问题是，总时间怎么定呢？倍数于你估计的单个运行时间？

事实上，总时间应该是基于你使用的宿主环境的定时器的精度来决定，这样能够最大限度的避免测量的误差。你使用的计时器精度越差，你就应运行更长的时间。比如之前提到的，对 IE浏览器的15毫秒精度的计时器而言，总时间设置为750毫秒(15*50)就能将不确定性的概率降低到 1% 以下(利用统计学中标准正态分布就能推导出)，如果是1毫秒精度的计时器，50毫秒总时间应该是相同的效果。

当然，仅仅一个样本是不够的，你还需要更多的样本来平滑掉异常的情况，而且你肯定希望知道最差的样本和最好的样本，以及他们之间的差异情况。你肯定得知道这段代码最短的耗时是多少，以及在多大的程度上能够信任它。显然，你还想要结合其他的技术方案，来作比较，而后挑选出最优的方案……

这些仅仅是开始而已，而若是你觉得太麻烦了，能不能省点事，那很遗憾的告诉你 —— "you don't know: proper benchmarking."

### Benchmark.js
统计学是讨论基准所必备的基础知识，如果你对 “标准差”、“方差”、“误差范围”、“置信区间”…… 这些术语感到陌生，不妨回顾下大学本科时的统计学，曾经教授过的这些基本概念。

当然，伟大的社区早已经有人贡献了方便趁手的工具，就叫 [Benchmark.js](http://benchmarkjs.com/)，所以直接拿来用没啥不好的：

```js
function foo () {
	// some code
}

var bench = new Benchmark(
	'foo test',
	foo,
	{
		// ...     // options
	}
);

bench.hz; // 每秒执行代码的数量
bench.stats.mean; // 算数平均数
bench.stats.moe; // 误差范围
bench.stats.variance; // 样本方差
bench.stats.deviation; // 样本标准差
```

毫不夸张的讲，Benchmark.js 是任何一个初次踏入JS代码的性能基准测试领域的开发者，都应该去尝试使用的一个库，👆🏻上面的示例仅仅是这个库的冰山一角，而诸如比较两个单独的代码块 X 和 Y 到底谁更快时，Benchmark.js 提供了一个叫做 "Suite" 的结构，你能够直接运行它们，而后就能拿到哪个更快的数据了。

无论是在浏览器还是在 Node.js 环境中，Benchmark.js 都提供了良好的支持。

另一个值得花时间考虑的方向是 性能回归测试 领域，就如同单元测试一样，在你的项目中书写好性能测试的用例，而后每次在项目部署前，都自动运行性能测试，以此达到自动监控本次提交的代码，是否对项目的性能造成了影响。

### Setup/Teardown
在初始化 Benchmark.js 的时候，第三个参数能够传递一些可选的配置项，其中有两个选项值得花时间讨论一番：`setup` 和 `teardown`。

Benchmark.js 的文档中是这么描述这两个选项的：
- `setup`: compiled/called before the test loop

- `teardown`: compiled/called after the test loop

这两个选项定义了在你测试代码运行之前，或者运行结束后的回调函数。但是要明白，它们不会在每次迭代的过程中都执行，而只会开始或者结束的时候，执行一次。

强调这一点是因为在某些涉及到 DOM 的测试中，比如往某个元素中追加子元素的操作，此时若是在 `setup` 或者 `teardown` 中有重置父元素的动作是无效的，而最终的结果是会导致DOM元素累积的越来越多，最终让测试的数据和实际的数据产生严重的背离。

## 注意上下文环境(Context Is King)
一个容易被忽视的地方：如果测试的结果是 X 比 Y 快，那么就一定能说 X 比 Y 快么？这仅仅是实验室的数据，别忘记你真实运行代码的时候，都是在一套独特的上下文环境中进行的 —— 比如在用户的某个版本的操作系统下的某个浏览器中。

而且，就算是 X 每秒能运行 10,000,000 次，而 Y 每秒“只能”运行 8,000,000 次 —— 当然从数学角度来讲，Y 比 X 慢 20% 是没有问题的。可是在现实中的确如此吗？

倒推一下不难发现，10,000,000 次每秒 就是 10,000 次每毫秒，再往下就是 10 次每微秒。换句话说，每一次 X 的执行只花了 0.1 微秒 或 100纳秒 —— 一般情况下，人们能够察觉的时间周期是 100毫秒 —— 从这个角度来看，别说 20%，哪怕 99% 的优势都显得毫无意义可言。

就算最新的科学报告说人类大脑的处理速度最快能到 13毫秒，可 X 运行一次的速度依然是这个数值的12.5万倍，而至于 X 和 Y 之间的差距，除非有百万甚至千万次连续的循环运行，否则大脑也根本感知不到差距。

说这么多，其实就是为了破除一种常见的迷思：纠结 “到底是 `++x` 还是 `x++` 更快” 这些细微的差别 —— 先不说能不能知道，就算得出结论，有用吗？

### 引擎的优化(Engine Optimizations)
“X 比 Y 快 10微秒” —— 这样的差距，什么都不是。

例如，对下面的一些 “微观层面的行为” 进行的测试比较(纯理论)：
```js
var twelve = "12";
var foo = "foo";

// 测试 1
var X1 = parseInt(twelve);
var X2 = parseInt(foo);

// 测试 2
var Y1 = Number(twelve);
var Y2 = Number(foo);
// 
```

或许你的直觉会认为 `parseInt(…)` 比 `Number(…)` 做的事情更多，因此更慢；又或许你的直觉告诉你，当参数是 `foo` 的时候，它们做的工作应该都一样 —— 碰到第一个是英文字母 `f` 就应该直接得出结论。

哪一种直觉更准确？或者说它们谁快谁慢真的重要吗？

假如，我们最后从统计学角度得到的答案是 X 和 Y 一样快，那就能说明关于字母 `f` 的直觉是正确的吗？

从理论上讲，一种可能的情况是 JS引擎 对这些操作都做了优化，比如强制将字符串的 `"12"` 转化成数字 `12`；又比如这些测试用例的变量，因为外币对其没有任何引用，所以干脆触发了 `dead-code` 机制，导致的结果是 JS引擎 根本就不会运行这些测试代码……

现代浏览器的 JS引擎 有很多优化的策略，而且很可能同一个浏览器不同的版本，优化的策略都不一样。同样的代码，很可能测试的时候触发了优化策略，而在实际运行的时候却没有，反之亦然。

因此，这种微观层面的比较，对于实际运行的代码，没有任何指导的意义。

但这并不意味着性能的测试都是无意义的。归根结底的问题在于，你没有用实际运行的代码去测试，所以结果也不能反映真实的情况。

所以诸如 `++x` 和 `x++` 的比较，毫无疑问是虚假且无意义的。

### 合理的测试(Sanity Check)
有一些看上去很合理，但实际上很荒谬的测试用例：

```js
// 用例 1
var x = [];
for (var i = 0; i < 10; i++) {
	x[i] = "x";
}

// 用例 2
var x = [];
for (var i = 0; i < 10; i++) {
	x[x.length] = "x";
}

// 用例 3
var x = [];
for (var i = 0; i < 10; i++) {
	x.push("x");
}
```

一些值得我们揣摩的地方：
- `for` 循环完全没有必要，因为 Benchmark.js 已经帮我们实现了这些需要重复的工作；

- 除非你有意要研究 JS引擎 在小数组下的表现，否则一开始的声明以及初始化 `x` 毫无必要，因为有 `setup` 可供使用；

- 测试用例的主旨是比较 `x[x.length]` 和 `x.push(…)` 相对于 `x[i]` 的影响，但显然 `push(…)` 是一个函数调用，毫无疑问会比 `[…]` 访问来得慢。这即意味着 用例1和用例2 一定比 用例3 更快。

下面是另一个常见的无效测试：

```js
// 用例 1
var x = ["John", "Albert", "Sue", "Frank", "Bob"];
x.sort();

// 用例 2
var x = ["John", "Albert", "Sue", "Frank", "Bob"];
x.sort(function mySort(a,b){
	if (a < b) return -1;
	if (a > b) return 1;
	return 0;
});
```

显然👆🏻想要比较的是 `sort()` 内置的比较函数和自定义的函数之间的差距。但依然，这样的测试显得很不公平，因为 用例2 不仅要测试函数本身的性能，还要加上每次声明新函数的开销。正确的做法是在外部定义好函数，而后直接引用即可。

继续用上面的例子看另一个无效的测试：

```js
// 用例 1
var x = [12, -14, 0, 3, 18, 0, 2.9];
x.sort();

// 用例 2
var x = [12, -14, 0, 3, 18, 0, 2.9];
x.sort(function mySort(a,b){
	return a - b;
});
```

除了之前提到的新建函数的开销之外，这个测试用例另一个无效的地方是 `sort(…)` 内置的函数显然比自定义的函数做的事情更多 —— 它会将数字隐式转换成字符串，而后在进行字母表的比较。用例1的结果是 `[-14, 0, 0, 12, 18, 2.9, 3]`，而用例2则为 `[-14, 0, 0, 2.9, 3, 12, 18]`。

另一个更微妙的陷阱：

```js
// 用例 1
var x = false;
var y = x ? 1 : 2;

// 用例 2
var x;
var y = x ? 1 : 2;
```

显然这两个测试的想比较是，三元操作符 `? :` 在判断 `x` 的时候，若是它一个非布尔值(Boolean)，是否做隐式转换。

乍一看好像没啥问题，可是你再仔细看看思考下？

`var x = false;` 和 `var x;` —— 前者可是多了一步赋值的操作啊？！

挺微妙的哈，那么，更精确的测试用例应该这么写：

```js
// 用例 1
var x = false;
var y = x ? 1 : 2;

// 用例 2
var x = undefined;
var y = x ? 1 : 2;
```

现在大家都有赋值过程了，所以得控制好每一个影响因素，才能得出更为精确的结论。

## 如何写出好的测试用例(Writing Good Tests)